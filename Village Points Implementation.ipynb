{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime, for logging\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "# Pandas, for reading excel files\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "# Mame sure the package openpyxl is installed to write to excel files\n",
    "\n",
    "# System stuff, for authentication and path stuff\n",
    "from __future__ import print_function\n",
    "import pickle\n",
    "import os.path\n",
    "import io\n",
    "from io import BytesIO\n",
    "\n",
    "# structs to help organize events\n",
    "from collections import namedtuple\n",
    "\n",
    "# Google stuff\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some constant variable definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some important variables that may change over time\n",
    "teamFolderName = \"HSV Fellows Team Folder\" # What is the exact name of the shared drive folder\n",
    "\n",
    "attendanceFolderName = \"Attendance Sheets\" # And where do we store attendance records\n",
    "\n",
    "outputSheetName = f\"CompiledList_{datetime.now()}.xlsx\"\n",
    "\n",
    "logFileName = f\"{datetime.now()}_output_log.txt\" # Where we will store all the output of the program\n",
    "\n",
    "debugMode = True # If this is enabled, all of the output will also be printed to the screen (as well as the log file)\n",
    "\n",
    "credentialsFileName = \"ncsu_credentials.json\" # The credentials file that you download from Google\n",
    "\n",
    "pickleFileName = \"token.pickle\" # Where the credentials will be stored\n",
    "\n",
    "attendanceFolderSearchDepth = 2 # How many levels of directories we should look to find the attendance\n",
    "\n",
    "downloadFolder = 'downloads' # Our downloads folder (make sure there isn't a trailing '/')\n",
    "\n",
    "Event = namedtuple(\"Event\", \"name date villagePoints hosts id\")\n",
    "\n",
    "# This is both the format that the excel files should use, and the one we use to compare dates internally\n",
    "dateFormat = \"%m/%d/%Y\"\n",
    "\n",
    "# The following two variables define the window in which we are looking for events\n",
    "lowerBoundDate = date(2020, 1, 1)\n",
    "upperBoundDate = date(2020, 1, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some simple methods that will help us with various things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will help us log the output of the program\n",
    "def log(string, alsoPrint):\n",
    "    with open(logFileName, \"a\") as logFileBuffer:\n",
    "        logFileBuffer.write(f\"[{datetime.now()}]:  {string}\\n\")\n",
    "        \n",
    "    if alsoPrint:\n",
    "        print(f\"[{datetime.now()}]:  {string}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to setup authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupAuthentication():\n",
    "    \n",
    "    creds = None\n",
    "    \n",
    "    #SCOPES = ['https://www.googleapis.com/auth/drive.file']\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "    \n",
    "    # The file token.pickle stores the user's access and refresh tokens, and is\n",
    "    # created automatically when the authorization flow completes for the first\n",
    "    # time.\n",
    "    if os.path.exists(pickleFileName):\n",
    "        with open(pickleFileName, 'rb') as token:\n",
    "            creds = pickle.load(token)\n",
    "            \n",
    "    # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        log(f\"Didn't find credentials from {pickleFileName}\", debugMode)\n",
    "        \n",
    "        # Either way set up the credentials\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "            log(f\"Refreshing credentials via Google\", debugMode)\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                credentialsFileName, SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "            log(f\"Refreshing credentials via secrets file {credentialsFileName}\", debugMode)\n",
    "            \n",
    "        # Save the credentials for the next run\n",
    "        with open(pickleFileName, 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "    else:\n",
    "        log(f\"Found credentials from {pickleFileName}\", debugMode)\n",
    "        \n",
    "    return creds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to find the Team folder ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findTeamFolderID(service):\n",
    "    \n",
    "    # This query string specifies that we are looking only for files that fit the mimetype in '', which means folders\n",
    "    queryString = \"mimeType = 'application/vnd.google-apps.folder'\"\n",
    "    # List all of the files that match our query\n",
    "    results = service.files().list(q=queryString, pageSize=300, fields=\"nextPageToken, files(name, id)\").execute()\n",
    "    # Now grab those bad boys so we can mess around with them\n",
    "    items = results.get('files', [])\n",
    "\n",
    "    # We are going eventually single out the Fellow Team Folder, and we will store its GDrive ID here\n",
    "    # This could also be found by looking at the long hexadecimal string in the url of the drive folder\n",
    "    # but we want to find it automatically\n",
    "    teamFolderID = None\n",
    "    \n",
    "    if not items:\n",
    "        # Hopefully we don't find nothing, but it we do we wanna stop\n",
    "        log('No files found in drive', debugMode)\n",
    "        return\n",
    "    else:\n",
    "        # Otherwise we wanna print out that we found the folder and save the ID\n",
    "        for item in items:\n",
    "            if item['name'] == teamFolderName:\n",
    "                log(u'Found team folder: ({0}, {1})'.format(item['name'], item['id']), debugMode)\n",
    "                teamFolderID = item['id']\n",
    "\n",
    "    if teamFolderID == None:\n",
    "        # We didn't find the team folder, which is bad\n",
    "        log('Team folder not found, try checking your team drive folder name and make sure it is exactly correct.', debugMode)\n",
    "        return\n",
    "    \n",
    "    return teamFolderID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to list files in a folder recursively (used in the next two methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursiveListFilesInFolder(rootFolderID, depth, mimeType):\n",
    "\n",
    "    queryString = \"'\" + rootFolderID + \"' in parents and not trashed\"\n",
    "    folderSearch = service.files().list(q=queryString, pageSize=100, fields=\"nextPageToken, files(name, id, mimeType)\").execute()\n",
    "    files = folderSearch.get('files', [])\n",
    "\n",
    "    allFiles = []\n",
    "\n",
    "    for file in files:\n",
    "        if file['mimeType'] == mimeType:\n",
    "            allFiles.append(file)\n",
    "        if depth != 0 and file['mimeType'] == 'application/vnd.google-apps.folder':\n",
    "            allFiles = allFiles + recursiveListFilesInFolder(file['id'], depth - 1, mimeType)\n",
    "\n",
    "    return allFiles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to find the Attendance folder ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAttendanceFolderID(teamFolderID, service):\n",
    "        \n",
    "    # Recursively look for folders in the team folder, so we can search for our attendance one\n",
    "    files = recursiveListFilesInFolder(teamFolderID, attendanceFolderSearchDepth, 'application/vnd.google-apps.folder')\n",
    "    \n",
    "    attendanceFolderID = None\n",
    "    # Look for our attendance folder\n",
    "    if not files:\n",
    "        log('No files found', debugMode)\n",
    "    else:\n",
    "        for file in files:\n",
    "            if file['name'] == attendanceFolderName:\n",
    "                log(u'Found attendance folder: ({0}, {1})'.format(file['name'], file['id']), debugMode)\n",
    "                attendanceFolderID = file['id']\n",
    "                \n",
    "    if attendanceFolderID == None:\n",
    "        # We didn't find the folder where attendance sheets are kept\n",
    "        log(f'Specified attendance folder not found, make sure that the folder name is exactly correct. You can also try increasing the search depth (current={attendanceFolderSearchDepth})', debugMode)\n",
    "        return\n",
    "    \n",
    "    return attendanceFolderID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to list all sheets in the attendance folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSheetIDInFolder(attendanceFolderID):\n",
    "    # A depth of -1 means it will search until there are no more directories left ie. infinite depth\n",
    "    # Let's just hope there aren't any symlinks in this folder :/\n",
    "    spreadsheets = recursiveListFilesInFolder(attendanceFolderID, -1, 'application/vnd.google-apps.spreadsheet')\n",
    "    \n",
    "    if len(spreadsheets) == 0:\n",
    "        log(f\"No spreadsheets found in attendance folder with ID {attendanceFolderID}\", debugMode)\n",
    "        return\n",
    "    \n",
    "    spreadsheetIDNames = [[spreadsheets[i][\"id\"], spreadsheets[i][\"name\"]] for i in range(len(spreadsheets))]\n",
    "    \n",
    "    for s in spreadsheets:\n",
    "        log(f\"Found sheet {s}\", debugMode)\n",
    "        \n",
    "    return spreadsheetIDNames\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to download all of the sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadSheets(sheetIDList, service):\n",
    "    \n",
    "    fileList = ['' for i in range(len(sheetIDList))]\n",
    "    \n",
    "    log(f\"Beginning download for {len(sheetIDList)} files\", debugMode)\n",
    "    \n",
    "    i = 0\n",
    "    for sheetID in sheetIDList:\n",
    "        \n",
    "        log(f\"Downloading file with ID {sheetID[0]} ({sheetID[1]})...\", debugMode)\n",
    "        \n",
    "        request = service.files().export_media(fileId=sheetID[0],\n",
    "                                                 mimeType='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')\n",
    "    \n",
    "        fh = io.BytesIO()\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while done is False:\n",
    "            status, done = downloader.next_chunk()\n",
    "        \n",
    "        with open(f\"{downloadFolder}/{sheetID[0]}.xlsx\", 'wb') as file:\n",
    "            file.write(fh.getvalue())\n",
    "        fh.close()\n",
    "        \n",
    "        fileList[i] = [f\"{downloadFolder}/{sheetID[0]}.xlsx\", sheetID[0], sheetID[1]]\n",
    "        i = i + 1\n",
    "        \n",
    "        log(f\"Download completed for file with ID {sheetID[0]} ({sheetID[1]}): saved to {downloadFolder}/{sheetID[0]}.xlsx\", debugMode)\n",
    "        \n",
    "    log(f\"Download for {len(sheetIDList)} files complete\", debugMode)\n",
    "\n",
    "    return fileList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The method to parse excel sheets for event/student info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseSheet(sheetFile):\n",
    "    \n",
    "    # The test file we will be working on\n",
    "    #sheetName = \"Career Studio Takeover.xlsx\"\n",
    "\n",
    "    #try:\n",
    "        # Load in the excel file using pandas\n",
    "    file = pd.read_excel(sheetFile[0], parse_dates=True)\n",
    "    #except:\n",
    "    #    log(f'File {sheetName} not found!', debugMode)\n",
    "    #    return None\n",
    "    \n",
    "    #print(file.columns)\n",
    "\n",
    "    # We can't expect that everyone will format the name exactly as it should be,\n",
    "    # so we want to identify what each header is actually called\n",
    "    # Below we have a list of words that should show up in one way or another for each category\n",
    "    keywords = {'Student ID':[\"id\", 'student', 'ncsu'],\n",
    "                'Event Name':['event', 'program', 'name'],\n",
    "                'Student Name':['name', 'first'],\n",
    "                'Village Points':['village', 'points', 'vp'],\n",
    "                'Hosts':['host', 'fellow', 'leader'],\n",
    "                'Date':['date', 'day', 'event', 'program']}\n",
    "    actualKeywords = {}\n",
    "\n",
    "    # These are characters that may show up that we don't want to influence the identification process\n",
    "    arbitraryChars = [':', '(', ')', '[', ']', '{', '}']\n",
    "\n",
    "    for header in file.columns:\n",
    "        # Make it lowercase\n",
    "        currHeader = header.lower()\n",
    "\n",
    "        # We want to ignore columns that don't have headers\n",
    "        if 'Unnamed' in header:\n",
    "            continue\n",
    "\n",
    "        # Remove semicolons\n",
    "        for c in arbitraryChars:\n",
    "            currHeader = currHeader.replace(c, '')\n",
    "\n",
    "        #print(currHeader)\n",
    "\n",
    "        qualifierMatches = {}\n",
    "        i = 0\n",
    "        for keyword, qualifiers in keywords.items():\n",
    "            qualifierMatches[keyword] = 0\n",
    "            for q in qualifiers:\n",
    "                if q in currHeader:\n",
    "                    qualifierMatches[keyword] = qualifierMatches[keyword] + 1\n",
    "\n",
    "            # This is kinda an obscure way of weighting things, but it seems to work for now\n",
    "            qualifierMatches[keyword] = float(qualifierMatches[keyword]) / (float(len(currHeader.split())) * float(len(keywords[keyword])))\n",
    "            i = i + 1\n",
    "\n",
    "        # Now we want to find which index of qualifierMatches has the highest value, which will become the actualKeyword\n",
    "        key = max(qualifierMatches, key=qualifierMatches.get)\n",
    "        #print(key)\n",
    "        actualKeywords[key] = header\n",
    "\n",
    "        #print(qualifierMatches)\n",
    "\n",
    "        \n",
    "    #print(actualKeywords)\n",
    "\n",
    "    # To rule out now properly formatted files, we should make sure that every value in our dictionary is unique\n",
    "    # ie. no two columns were assigned to the same header string or vice versa\n",
    "    # We do this by flipping our dictionary and making sure the length stays the same, since keys must be unique\n",
    "    flippedKeywords = {}\n",
    "    for k, v in actualKeywords.items():\n",
    "        flippedKeywords[v] = k\n",
    "    \n",
    "    #print(len(flippedKeywords))\n",
    "    #print(len(keywords))\n",
    "    \n",
    "    if not len(flippedKeywords) == len(keywords):\n",
    "        log(f\"ERROR: Headers in file {sheetFile[0]} ({sheetFile[2]}) are not formatted properly, ignoring this file!\", debugMode)\n",
    "        return None\n",
    "    \n",
    "    # We now know where all of our information is, so we should start grabbing it\n",
    "    \n",
    "    \n",
    "    villagePoints = None\n",
    "    # We now know where all of our information is, so we should start grabbing it\n",
    "    possibleVillagePoints = file[actualKeywords['Village Points']].dropna().values.tolist()\n",
    "    #print(possibleVillagePoints)\n",
    "    \n",
    "    if isinstance(possibleVillagePoints, list):\n",
    "        if len(possibleVillagePoints) == 1:\n",
    "            villagePoints = possibleVillagePoints[0]\n",
    "            log(f\"Found value for village points: {villagePoints} in file {sheetFile[0]} ({sheetFile[2]})\", debugMode)\n",
    "        elif len(possibleVillagePoints) > 1:\n",
    "            log(f\"Warning: more than one populated cell under header {actualKeywords['VillagePoints']}; attempting to take first value\", debugMode)\n",
    "            villagePoints = possibleVillagePoints[0]\n",
    "            log(f\"Found value for village points: {villagePoints} in file {sheetFile[0]} ({sheetFile[2]})\", debugMode)\n",
    "        else:\n",
    "            log(f\"ERROR: Village point value for {sheetFile[0]} ({sheetFile[2]}) not specified, ignoring this file!\", debugMode)\n",
    "            return None\n",
    "    else:\n",
    "        villagePoints = possibleVillagePoints\n",
    "        log(f\"Found value for village points: {villagePoints} in file {sheetFile[0]} ({sheetFile[2]})\", debugMode)\n",
    "\n",
    "    eventDate = None\n",
    "    # Find our possible dates\n",
    "    \n",
    "    # We have to have an extra try except here since if there is no date, the .dt will get mad\n",
    "    try:\n",
    "        possibleDates = file[actualKeywords['Date']].dropna().dt.strftime('%m/%d/%Y').values.tolist()\n",
    "    except:\n",
    "        log(f\"ERROR: Event date for {sheetFile[0]} ({sheetFile[2]}) not specified, ignoring this file!\", debugMode)\n",
    "        return None\n",
    "    #print(possibleDates)\n",
    "        \n",
    "    if isinstance(possibleDates, list):\n",
    "        if len(possibleDates) == 1:\n",
    "            eventDate = possibleDates[0]\n",
    "            log(f\"Found value for event date: {eventDate} in file {sheetFile[0]} ({sheetFile[2]})\", debugMode)\n",
    "        elif len(possibleDates) > 1:\n",
    "            log(f\"Warning: more than one populated cell under header {actualKeywords['Date']}; attempting to take first value\", debugMode)\n",
    "            eventDate = possibleDates[0]\n",
    "            log(f\"Found value for event date: {eventDate} in file {sheetFile[0]} ({sheetFile[2]})\", debugMode)\n",
    "\n",
    "        else:\n",
    "            log(f\"ERROR: Event date for {sheetFile[0]} ({sheetFile[2]}) not specified, ignoring this file!\", debugMode)\n",
    "            return None\n",
    "    else:\n",
    "        eventDate = possibleDates\n",
    "        log(f\"Found value for event date: {eventDate} in file {sheetFile[0]} ({sheetFile[2]})\", debugMode)\n",
    "    \n",
    "    \n",
    "    hosts = None\n",
    "    possibleHosts = file[actualKeywords['Hosts']].dropna().values.tolist()\n",
    "    #print(possibleHosts)\n",
    "    \n",
    "    if isinstance(possibleHosts, list):\n",
    "        # We can have more than one host, so this is alright to have more than one cell populated\n",
    "        if len(possibleHosts) >= 1:\n",
    "            hosts = possibleHosts[0]\n",
    "            log(f\"Found value for hosts: {hosts} in file {sheetFile[0]} ({sheetFile[2]})\", debugMode)\n",
    "        else:\n",
    "            log(f\"ERROR: Hosts for {sheetFile[0]} ({sheetFile[2]}) not specified, ignoring this file!\", debugMode)\n",
    "            return None\n",
    "    else:\n",
    "        hosts = possibleHosts\n",
    "        log(f\"Found value for hosts: {hosts} in file {sheetFile[0]} ({sheetFile[2]})\", debugMode)\n",
    "\n",
    "    eventName = None\n",
    "    possibleNames = file[actualKeywords['Event Name']].dropna().values.tolist()\n",
    "    #print(possibleNames)\n",
    "    \n",
    "    if isinstance(possibleNames, list):\n",
    "        if len(possibleNames) == 1:\n",
    "            eventName = possibleNames[0]\n",
    "            log(f\"Found value for event name: {eventName} in file {sheetFile[0]} ({sheetFile[2]})\", debugMode)\n",
    "        elif len(possibleNames) > 1:\n",
    "            log(f\"Warning: more than one populated cell under header {actualKeywords['Event Name']}; attempting to take first value\", debugMode)\n",
    "            eventName = possibleNames[0]\n",
    "            log(f\"Found value for event date: {eventName} in file {sheetFile[0]} ({sheetFile[2]})\", debugMode)\n",
    "        else:\n",
    "            log(f\"ERROR: Event name for {sheetFile[0]} ({sheetFile[2]}) not specified, ignoring this file!\", debugMode)\n",
    "            return None\n",
    "    else:\n",
    "        eventName = possibleNames\n",
    "        log(f\"Found value for event name: {eventName} in file {sheetFile[0]} ({sheetFile[2]})\", debugMode)\n",
    "\n",
    "    # Create a struct for the event\n",
    "    event = Event(eventName, eventDate, villagePoints, hosts, sheetFile[1])\n",
    "    \n",
    "    #print([villagePoints, eventDate, hosts, eventName])\n",
    "\n",
    "    students = file[actualKeywords['Student ID']].dropna().values.tolist()\n",
    "    #print(students)\n",
    "    \n",
    "    # Now that we have all of the information about the event, we should return all of the students who atended and the information about the event\n",
    "    return [event, students]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The method to save the student files to a sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveStudentsToFile(studentList):\n",
    "    \n",
    "    # Pandas is kinda weird in that every column we write has to have the same length\n",
    "    # This means that our column with generation data, since it alwaus has the same number\n",
    "    # of columns, is the minimum number of columns (ie students) that we can run this program with\n",
    "    # I know it seems stupid, but I don't think it's very important to fix right now\n",
    "    if len(studentList) < 7:\n",
    "        log(f\"ERROR: Attempting to run program with less than 7 students, see method saveStudentsToFile for why this is invalid! Exiting...\", debugMode)\n",
    "        return\n",
    "    \n",
    "    # We will use this method to have the name of each event hyperlink to that attendance sheet\n",
    "    def createLink(eventName, sheetID):\n",
    "        return f\"=HYPERLINK(\\\"https://docs.google.com/spreadsheets/d/{sheetID}\\\", \\\"{eventName}\\\")\"\n",
    "            \n",
    "    # We've got to set up our data in columns so that it's easy to write\n",
    "    # The student ID column is easy, we pretty much already have it\n",
    "    studentIDList = list(studentList.keys())\n",
    "        \n",
    "    # Now iterate over every event for each student to get the rest of the info\n",
    "    totalVillagePoints = [0 for i in range(len(studentIDList))]\n",
    "    # Since excel and google sheets can only handle one hyperlink per cell, we will just have the\n",
    "    # rest of the columns as space to hold one event per cell\n",
    "    # Because of this, our list of events is actually 2D\n",
    "    studentListOfEvents = [[] for i in range(len(studentIDList))]\n",
    "    i = 0\n",
    "    for ID, events in studentList.items():\n",
    "        # We have to handle the case where there is only one event (and so python turns lists with only one element into just that element)\n",
    "        if not isinstance(events, list):\n",
    "            totalVillagePoints[i] = events.villagePoints\n",
    "            studentListOfEvents[i] = [createLink(events.name, events.id)]\n",
    "        else:\n",
    "            for e in events:\n",
    "                totalVillagePoints[i] = totalVillagePoints[i] + e.villagePoints\n",
    "                studentListOfEvents[i] = studentListOfEvents[i] + [createLink(e.name, e.id)]\n",
    "            \n",
    "        i = i + 1\n",
    "        \n",
    "        \n",
    "    #print(studentListOfEvents)\n",
    "    \n",
    "    # We now have to do a bit of reorganzing so that our events are easily writable\n",
    "    maxColumns = max([len(elem) if isinstance(elem, list) else 1 for elem in studentListOfEvents])\n",
    "    rectangularEventLists = [[\"\" for j in range(len(studentIDList))] for i in range(maxColumns)]\n",
    "    \n",
    "    for i in range(len(studentIDList)):\n",
    "        if isinstance(studentListOfEvents[i], list):\n",
    "            for j in range(len(studentListOfEvents[i])):\n",
    "                rectangularEventLists[j][i] = studentListOfEvents[i][j]\n",
    "        else:\n",
    "            rectangularEventLists[j][i] = studentListOfEvents[i]\n",
    "    \n",
    "    writableEventColumns = {}\n",
    "    \n",
    "    if isinstance(rectangularEventLists[0], list) and len(rectangularEventLists[0]) > 1:\n",
    "    \n",
    "        writableEventColumns[\"Events (1)\"] = rectangularEventLists[0]\n",
    "\n",
    "        for i in range(maxColumns - 1):\n",
    "            writableEventColumns[f\"{i+2}\"] = rectangularEventLists[:][i+1]\n",
    "\n",
    "    else:\n",
    "        writableEventColumns[\"Events\"] = rectangularEventLists[0][:]\n",
    "    \n",
    "    # The first column will just be full of generation info\n",
    "    # We have to make a lot of empty cells since every column has to have the same length\n",
    "    generationInfo = [\"\" for i in range(len(studentIDList))]\n",
    "    generationInfo[0] = \"Begin date:\"\n",
    "    generationInfo[1] = f\"{lowerBoundDate}\"\n",
    "    generationInfo[3] = \"End date:\"\n",
    "    generationInfo[4] = f\"{upperBoundDate}\"\n",
    "    generationInfo[6] = \"Execution date:\"\n",
    "    generationInfo[7] = f\"{datetime.now()}\"\n",
    "\n",
    "    allColumns = {\"Generation Info\":generationInfo, \"Student ID:\":studentIDList, \"Village Points:\":totalVillagePoints}\n",
    "    allColumns.update(writableEventColumns)\n",
    "    \n",
    "    log(f\"Data manipulation for writing to file complete, beginning writing process!\", debugMode)\n",
    "    \n",
    "    #print(allColumns)\n",
    "    \n",
    "    #for j, k in allColumns.items():\n",
    "    #    print(len(k))\n",
    "    \n",
    "    #print(f\"{len(generationInfo)} {len(studentIDList)} {len(totalVillagePoints)}\")\n",
    "    \n",
    "    # Now we actually write to the file\n",
    "    fileWriter = ExcelWriter(outputSheetName)\n",
    "    log(f\"Writing database to {outputSheetName}\", debugMode)\n",
    "    \n",
    "    #data = pd.DataFrame([generationInfo, studentIDList, totalVillagePoints])\n",
    "    data = pd.DataFrame(allColumns)\n",
    "    data.to_excel(fileWriter,\"Sheet1\",index=False)\n",
    "    fileWriter.save()\n",
    "    \n",
    "    log(f\"Writing process completed successfully!\", debugMode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The method to upload the sheet to drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uploadSheetAndLogToDrive(service, attendanceFolderID):\n",
    "    \n",
    "    log(f\"Beginning upload of compiled list into parent folder with ID {attendanceFolderID}\", debugMode)\n",
    "    \n",
    "    # Our file is of type excel spreadsheet, but we can easily convert it to a google sheet format here\n",
    "    sheetMetadata = {\"name\":outputSheetName,\n",
    "                   \"mimeType\":\"application/vnd.google-apps.spreadsheet\",\n",
    "                   \"parents\":[attendanceFolderID]}\n",
    "    \n",
    "    # Specifiy the original mimetype, not what it will end up as here (see above)\n",
    "    sheetMedia = MediaFileUpload(outputSheetName,\n",
    "                           mimetype=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\",\n",
    "                           resumable=True)\n",
    "    \n",
    "    sheetUploadedFile = service.files().create(body=sheetMetadata,\n",
    "                                 media_body=sheetMedia,\n",
    "                                 fields='id').execute()\n",
    "    \n",
    "    log(f\"Uploaded compiled sheet to specified attendance folder completed successfully!\", debugMode)\n",
    "    log(f\"Uploaded file has ID {sheetUploadedFile.get('id')}\", debugMode)\n",
    "    \n",
    "    log(f\"Beginning upload of log file into parent folder with ID {attendanceFolderID}\", debugMode)\n",
    "    \n",
    "    # Not as complex as the above expression\n",
    "    logMetadata = {\"name\":logFileName,\n",
    "                      \"parents\":[attendanceFolderID]}\n",
    "    \n",
    "    log(f\"Log must end here, since file is being uploaded, for final status updates, see local copy of log.\", debugMode)\n",
    "    log(f\"See you space cowboy...\", debugMode)\n",
    "    \n",
    "    # Specifiy the original mimetype, not what it will end up as here (see above)\n",
    "    logMedia = MediaFileUpload(logFileName,\n",
    "                           mimetype=\"text/plain\",\n",
    "                           resumable=True)\n",
    "    \n",
    "    logUploadedFile = service.files().create(body=logMetadata,\n",
    "                                 media_body=logMedia,\n",
    "                                 fields='id').execute()\n",
    "    \n",
    "    log(f\"Uploaded log file to specified attendance folder completed successfully!\", debugMode)\n",
    "    log(f\"Uploaded file has ID {logUploadedFile.get('id')}\", debugMode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The method to delete all of the downloaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanUpDownloadFolder():\n",
    "    \n",
    "    files = os.listdir(downloadFolder)\n",
    "    \n",
    "    log(f'Removing {len(files)} files from {downloadFolder}', debugMode)\n",
    "    \n",
    "    for f in files:\n",
    "        os.remove(f'{downloadFolder}/{f}')\n",
    "        log(f'Removed file {downloadFolder}/{f})', debugMode)\n",
    "    \n",
    "    log(f'Removed {len(files)} files', debugMode)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we want to setup our credentials\n",
    "creds = setupAuthentication()\n",
    "\n",
    "# Create an object to interact with Google Drive\n",
    "service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "# Fetch the team folder ID\n",
    "teamFolderID = findTeamFolderID(service)\n",
    "\n",
    "# Find the attendance folder\n",
    "attendanceFolderID = findAttendanceFolderID(teamFolderID, service)\n",
    "\n",
    "# List all of the sheets inside the attendance folder\n",
    "sheetIDList = getSheetIDInFolder(attendanceFolderID)\n",
    "\n",
    "# Download all of the sheets and get a list of file names\n",
    "fileList = downloadSheets(sheetIDList, service)\n",
    "\n",
    "studentList = {}\n",
    "\n",
    "for file in fileList:\n",
    "    results = parseSheet(file)\n",
    "    \n",
    "    if results == None:\n",
    "        continue\n",
    "    \n",
    "    # Make sure that the date is within the range we want\n",
    "    # Not that we also have to cast from a datetime object to a date object\n",
    "    actualDate = datetime.date(datetime.strptime(results[0].date, dateFormat))\n",
    "    if actualDate < lowerBoundDate or actualDate > upperBoundDate:\n",
    "        log(f\"WARNING: Event {results[0].name} has date outside of specified range, ignoring this file!\", debugMode)\n",
    "        continue\n",
    "        \n",
    "    for s in results[1]:\n",
    "        try:\n",
    "            studentList[int(s)] = [studentList[s]] + [results[0]]\n",
    "        except:\n",
    "            studentList[int(s)] = results[0]\n",
    "\n",
    "# Save everything in a nice format\n",
    "saveStudentsToFile(studentList)\n",
    "\n",
    "# And remove all of the files we downloaded\n",
    "cleanUpDownloadFolder()\n",
    "\n",
    "# Upload to our attendance folder\n",
    "uploadSheetAndLogToDrive(service, attendanceFolderID)\n",
    "\n",
    "# This won't actually show up in the drive since the file is uploaded before this, but :/\n",
    "log(\"Execution completed\", debugMode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
